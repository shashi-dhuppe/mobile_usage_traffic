{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "import time\n",
    "from pyspark.sql import functions as fn\n",
    "from pyspark.ml import feature, regression, Pipeline\n",
    "\n",
    "import datetime\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, minute, second\n",
    "from pyspark.mllib.stat import Statistics\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "spark = SparkSession.builder.appName('data-cleaning').\\\n",
    "                        config(\"spark.executor.instances\", '3').\\\n",
    "                        config(\"spark.executor.memory\", '40g').\\\n",
    "                        config('spark.executor.cores', '5').\\\n",
    "                        config('spark.cores.max', '5').appName('data_clean').\\\n",
    "                        getOrCreate()\n",
    "\n",
    "sqlContext = SQLContext(spark.sparkContext)\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml import feature\n",
    "from pyspark.ml import classification\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator, RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = spark.read.format('csv').option('header', 'true').load('../data/spark_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data.select('town').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, validation, test = train_data.randomSplit([0.7, 0.2, 0.1], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_columns = ['device_id', 'app_id', 'label_id', 'event_id', 'longitude', 'latitude']\n",
    "int_columns = ['is_active', 'age', 'is_installed', 'day', 'hour', 'minute', 'seconds']\n",
    "string_columns = ['gender', 'phone_brand', 'device_model', 'town', 'country', 'category_mapped', 'time_of_day', 'age_group']\n",
    "\n",
    "training = training.select(*(col(c).cast(\"float\").alias(c) for c in float_columns), \\\n",
    "                                                 *(col(c).cast(\"int\").alias(c) for c in int_columns), \\\n",
    "                                                 *(col(c).alias(c) for c in string_columns))\n",
    "\n",
    "validation = validation.select(*(col(c).cast(\"float\").alias(c) for c in float_columns), \\\n",
    "                                                 *(col(c).cast(\"int\").alias(c) for c in int_columns), \\\n",
    "                                                 *(col(c).alias(c) for c in string_columns))\n",
    "\n",
    "test = test.select(*(col(c).cast(\"float\").alias(c) for c in float_columns), \\\n",
    "                                                 *(col(c).cast(\"int\").alias(c) for c in int_columns), \\\n",
    "                                                 *(col(c).alias(c) for c in string_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #PCA for town\n",
    "\n",
    "# gender_indexer = feature.StringIndexer(inputCol=\"gender\", outputCol=\"gender_label\",handleInvalid='skip')\n",
    "# category_indexer = feature.StringIndexer(inputCol='category_mapped', outputCol='category_encoded',handleInvalid='skip')\n",
    "# phone_brand_indexer = feature.StringIndexer(inputCol='phone_brand', outputCol='phone_brand_encoded',handleInvalid='skip')\n",
    "# is_active_indexer = feature.StringIndexer(inputCol='is_active', outputCol='is_active_encoded',handleInvalid='skip')\n",
    "# device_model_indexer = feature.StringIndexer(inputCol='device_model', outputCol='device_model_encoded',handleInvalid='skip')\n",
    "# town_indexer = feature.StringIndexer(inputCol='town', outputCol='town_encoded',handleInvalid='skip')\n",
    "# country_indexer = feature.StringIndexer(inputCol='country', outputCol='country_encoded',handleInvalid='skip')\n",
    "# time_of_day_indexer = feature.StringIndexer(inputCol='time_of_day', outputCol='time_of_day_encoded',handleInvalid='skip')\n",
    "# age_group_indexer = feature.StringIndexer(inputCol='age_group', outputCol='age_group_encoded',handleInvalid='skip')\n",
    "# #area_cluster_id_indexer = feature.StringIndexer(inputCol='area_cluster_id', outputCol='area_cluster_id_encoded',handleInvalid='skip')\n",
    "\n",
    "# vector_assembler = feature.VectorAssembler(inputCols=['device_id', 'app_id', 'label_id', 'event_id', 'is_active',\\\n",
    "#                                                       'device_model_encoded', 'phone_brand_encoded', 'gender_label', 'country_encoded',\\\n",
    "#                                                       'time_of_day_encoded', 'age_group_encoded', 'category_encoded'],\n",
    "#                                         outputCol='features')\n",
    "# sc = feature.StandardScaler(inputCol='features',outputCol='sfeatures')\n",
    "\n",
    "# evaluator = BinaryClassificationEvaluator(labelCol='gender_label')\n",
    "\n",
    "# pipe_prep_location=Pipeline(stages=[gender_indexer, category_indexer,phone_brand_indexer, is_active_indexer, device_model_indexer,\\\n",
    "#                            town_indexer, country_indexer, time_of_day_indexer, age_group_indexer, \\\n",
    "#                            vector_assembler, sc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.clustering import KMeans\n",
    "\n",
    "# # df_kmeans.show()\n",
    "# df_kmeans = pipe_prep_location.fit(training).transform(training)\n",
    "# cost = np.zeros(30)\n",
    "# for k in range(2,30):\n",
    "#     kmeans = KMeans().setK(k).setSeed(1).setFeaturesCol(\"sfeatures\")\n",
    "#     model = kmeans.fit(df_kmeans.sample(False,0.1, seed=42))\n",
    "#     cost[k] = model.computeCost(df_kmeans) # requires Spark 2.0 or later\n",
    "    \n",
    "# fig, ax = plt.subplots(1,1, figsize =(8,6))\n",
    "# ax.plot(range(2,30),cost[2:30])\n",
    "# ax.set_xlabel('k')\n",
    "# ax.set_ylabel('cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.clustering import KMeans\n",
    "# k = 30\n",
    "# df_kmeans = pipe_prep_location.fit(train_data).transform(train_data)\n",
    "# kmeans = KMeans().setK(k).setSeed(1).setFeaturesCol(\"sfeatures\")\n",
    "# model = kmeans.fit(df_kmeans)\n",
    "# centers = model.clusterCenters()\n",
    "\n",
    "# print(\"Cluster Centers: \")\n",
    "# for center in centers:\n",
    "#     print(center)\n",
    "\n",
    "# new_data = model.transform(df_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender Pipeline\n",
    "gender_indexer = feature.StringIndexer(inputCol=\"gender\", outputCol=\"gender_label\",handleInvalid='skip')\n",
    "category_indexer = feature.StringIndexer(inputCol='category_mapped', outputCol='category_encoded',handleInvalid='skip')\n",
    "phone_brand_indexer = feature.StringIndexer(inputCol='phone_brand', outputCol='phone_brand_encoded',handleInvalid='skip')\n",
    "is_active_indexer = feature.StringIndexer(inputCol='is_active', outputCol='is_active_encoded',handleInvalid='skip')\n",
    "device_model_indexer = feature.StringIndexer(inputCol='device_model', outputCol='device_model_encoded',handleInvalid='skip')\n",
    "town_indexer = feature.StringIndexer(inputCol='town', outputCol='town_encoded',handleInvalid='skip')\n",
    "country_indexer = feature.StringIndexer(inputCol='country', outputCol='country_encoded',handleInvalid='skip')\n",
    "time_of_day_indexer = feature.StringIndexer(inputCol='time_of_day', outputCol='time_of_day_encoded',handleInvalid='skip')\n",
    "age_group_indexer = feature.StringIndexer(inputCol='age_group', outputCol='age_group_encoded',handleInvalid='skip')\n",
    "#area_cluster_id_indexer = feature.StringIndexer(inputCol='area_cluster_id', outputCol='area_cluster_id_encoded',handleInvalid='skip')\n",
    "\n",
    "vector_assembler = feature.VectorAssembler(inputCols=['device_id', 'app_id', 'label_id', 'event_id', 'is_active',\\\n",
    "                                                      'device_model_encoded', 'phone_brand_encoded', 'town_encoded', 'country_encoded',\\\n",
    "                                                      'time_of_day_encoded', 'age_group_encoded', 'category_encoded'],\n",
    "                                        outputCol='features')\n",
    "sc = feature.StandardScaler(inputCol='features',outputCol='sfeatures')\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='gender_label')\n",
    "\n",
    "pipe_prep=Pipeline(stages=[gender_indexer, category_indexer,phone_brand_indexer, is_active_indexer, device_model_indexer,\\\n",
    "                           town_indexer, country_indexer, time_of_day_indexer, age_group_indexer, \\\n",
    "                           vector_assembler, sc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=feature.PCA(k=2, inputCol='sfeatures', outputCol='pfeat')\n",
    "\n",
    "pipe_pca=Pipeline(stages=[pipe_prep,pca]).fit(training)\n",
    "\n",
    "pca_mod=pipe_pca.transform(training)\n",
    "\n",
    "feat=train_data.columns\n",
    "actfeat=['device_id', 'app_id', 'label_id', 'event_id', 'is_active',\\\n",
    "                                                      'device_model_encoded', 'phone_brand_encoded', 'town_encoded', 'country_encoded',\\\n",
    "                                                      'time_of_day_encoded', 'age_group_encoded', 'category_encoded']\n",
    "\n",
    "# feat\n",
    "\n",
    "# actfeat=pca_mod.columns\n",
    "\n",
    "pca=pipe_pca.stages[1].pc.toArray()\n",
    "\n",
    "pc1_df=pd.DataFrame([pca[:, 0],actfeat]).T.rename(columns={0:'pc1',1:'abs_loadings'})\n",
    "pc2_df=pd.DataFrame([pca[:, 1],actfeat]).T.rename(columns={0:'pc2',1:'abs_loadings'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1_df.pc1=pc1_df.pc1.abs()\n",
    "\n",
    "pc1_df.sort_values(by=['pc1'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc2_df.pc2=pc2_df.pc2.abs()\n",
    "\n",
    "pc2_df.sort_values(by=['pc2'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic with default or no parameters\n",
    "\n",
    "logistic = classification.LogisticRegression(labelCol='gender_label', featuresCol='sfeatures')\n",
    "\n",
    "lr_pipe = Pipeline(stages=[pipe_prep, logistic]).fit(training)\n",
    "\n",
    "result1=evaluator.evaluate(lr_pipe.transform(test))\n",
    "\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc = evaluator.evaluate(lr_pipe.transform(test), {evaluator.metricName: \"areaUnderROC\"})\n",
    "auprc = evaluator.evaluate(lr_pipe.transform(test), {evaluator.metricName: \"areaUnderPR\"})\n",
    "print(\"Area under ROC Curve: {:.4f}\".format(auroc))\n",
    "print(\"Area under PR Curve: {:.4f}\".format(auprc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "lr_pipe = Pipeline(stages=[pipe_prep, logistic])\n",
    "\n",
    "lr_param = ParamGridBuilder() \\\n",
    "    .addGrid(logistic.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .addGrid(logistic.regParam, [0.1, 0.01]) \\\n",
    "    .build()\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"gender_label\", metricName='areaUnderROC')\n",
    "#evaluator = RegressionEvaluator(labelCol=\"town_encoded\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "#evaluator = MulticlassClassificationEvaluator(labelCol = 'town_encoded', predictionCol='prediction', metricName = 'accuracy')\n",
    "crossval = CrossValidator(estimator=lr_pipe,\n",
    "                         estimatorParamMaps=lr_param,\n",
    "                         evaluator=evaluator,\n",
    "                         numFolds=3)\n",
    "\n",
    "cvmodel = crossval.fit(validation)\n",
    "cvmodel.bestModel.stages[-1].extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF\n",
    "\n",
    "rf=classification.RandomForestClassifier(labelCol='gender_label', featuresCol='sfeatures')\n",
    "\n",
    "rf_pipe=Pipeline(stages=[pipe_prep,rf]).fit(training)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol = 'gender_label', metricName ='areaUnderROC')\n",
    "\n",
    "resultrf4=evaluator.evaluate(rf_pipe.transform(validation))\n",
    "\n",
    "resultrf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "rf_pipe=Pipeline(stages=[pipe_prep,rf])\n",
    "\n",
    "rfParam = ParamGridBuilder() \\\n",
    ".addGrid(rf.maxDepth, [4, 6, 8, 10]) \\\n",
    ".addGrid(rf.maxBins, [5, 10, 20]) \\\n",
    ".addGrid(rf.impurity, [\"gini\"]) \\\n",
    ".build()\n",
    "\n",
    "# gbtParam = (ParamGridBuilder()\n",
    "#              .addGrid(gbt.maxDepth, [4, 6, 8, 10])\n",
    "#              .addGrid(gbt.maxBins, [5, 10, 20, 40])\n",
    "#              .addGrid(gbt.maxIter, [5, 10, 15])\n",
    "#              .build())\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"gender_label\", metricName='areaUnderROC')\n",
    "#evaluator = RegressionEvaluator(labelCol=\"town_encoded\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "#evaluator = MulticlassClassificationEvaluator(labelCol = 'town_encoded', predictionCol='prediction', metricName = 'accuracy')\n",
    "crossval = CrossValidator(estimator=rf_pipe,\n",
    "                         estimatorParamMaps=rfParam,\n",
    "                         evaluator=evaluator,\n",
    "                         numFolds=3)\n",
    "\n",
    "#cv = CrossValidator(estimator=random_forest_pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "cvmodel = crossval.fit(validation)\n",
    "cvmodel.bestModel.stages[-1].extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF\n",
    "rf=classification.RandomForestClassifier(labelCol='gender_label', featuresCol='sfeatures', \\\n",
    "                                         maxDepth=10, maxBins=20, numTrees=20)\n",
    "\n",
    "rf_pipe=Pipeline(stages=[pipe_prep,rf]).fit(training)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"gender_label\", metricName='areaUnderROC')\n",
    "resultrf4=evaluator.evaluate(rf_pipe.transform(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc = evaluator.evaluate(rf_pipe.transform(test), {evaluator.metricName: \"areaUnderROC\"})\n",
    "auprc = evaluator.evaluate(rf_pipe.transform(test), {evaluator.metricName: \"areaUnderPR\"})\n",
    "print(\"Area under ROC Curve: {:.4f}\".format(auroc))\n",
    "print(\"Area under PR Curve: {:.4f}\".format(auprc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GBT without Cross Validation\n",
    "\n",
    "gbt = classification.GBTClassifier(labelCol='gender_label', featuresCol='sfeatures')\n",
    "gbt_pipe=Pipeline(stages=[pipe_prep,gbt]).fit(training)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"gender_label\", metricName='areaUnderROC')\n",
    "\n",
    "resultrf4=evaluator.evaluate(gbt_pipe.transform(test))\n",
    "\n",
    "resultrf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBT Cross Validation\n",
    "\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "gbt_pipe = Pipeline(stages=[pipe_prep, gbt])\n",
    "\n",
    "gbtParam = (ParamGridBuilder()\n",
    "             .addGrid(gbt.maxDepth, [4, 6, 8, 10])\n",
    "             .addGrid(gbt.maxBins, [5, 10, 20])\n",
    "             .addGrid(gbt.maxIter, [2])\n",
    "             .build())\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"gender_label\", metricName='areaUnderROC')\n",
    "#evaluator = RegressionEvaluator(labelCol=\"town_encoded\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "#evaluator = MulticlassClassificationEvaluator(labelCol = 'gender_label', predictionCol='prediction', metricName = 'accuracy')\n",
    "crossval = CrossValidator(estimator=gbt_pipe,\n",
    "                         estimatorParamMaps=gbtParam,\n",
    "                         evaluator=evaluator,\n",
    "                         numFolds=3)\n",
    "\n",
    "#cv = CrossValidator(estimator=random_forest_pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "\n",
    "cvmodel = crossval.fit(validation)\n",
    "cvmodel.bestModel.stages[-1].extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = classification.GBTClassifier(labelCol='gender_label', featuresCol='sfeatures', maxDepth=10, maxBins=20, lossType = 'logistic', maxIter=2)\n",
    "gbt_pipe=Pipeline(stages=[pipe_prep,gbt]).fit(training)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"gender_label\", metricName='areaUnderROC')\n",
    "\n",
    "resultrf4=evaluator.evaluate(gbt_pipe.transform(test))\n",
    "\n",
    "resultrf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc = evaluator.evaluate(gbt_pipe.transform(test), {evaluator.metricName: \"areaUnderROC\"})\n",
    "auprc = evaluator.evaluate(gbt_pipe.transform(test), {evaluator.metricName: \"areaUnderPR\"})\n",
    "print(\"Area under ROC Curve: {:.4f}\".format(auroc))\n",
    "print(\"Area under PR Curve: {:.4f}\".format(auprc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
